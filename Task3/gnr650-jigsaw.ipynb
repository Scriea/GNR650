{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# JIGSAW SSL","metadata":{"id":"uJcElzhxztq9"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.utils.data as data\nfrom torch import cat\nfrom PIL import Image\nnp.random.seed(0)\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\n!pip install grad-cam","metadata":{"id":"EC4U_2QZzj2p","execution":{"iopub.status.busy":"2023-10-15T14:20:43.021919Z","iopub.execute_input":"2023-10-15T14:20:43.022235Z","iopub.status.idle":"2023-10-15T14:21:02.195964Z","shell.execute_reply.started":"2023-10-15T14:20:43.022210Z","shell.execute_reply":"2023-10-15T14:21:02.194649Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Collecting grad-cam\n  Downloading grad-cam-1.4.8.tar.gz (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.23.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from grad-cam) (9.5.0)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (2.0.0)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (0.15.1)\nCollecting ttach (from grad-cam)\n  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.66.1)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.8.0.76)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from grad-cam) (3.7.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->grad-cam) (2.31.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (21.3)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (2.8.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.11.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\nBuilding wheels for collected packages: grad-cam\n  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.4.8-py3-none-any.whl size=38243 sha256=831f236f04b441d3a05e6a57f3a6c354ed5a6049ece7893d44cfa28189ca955d\n  Stored in directory: /root/.cache/pip/wheels/f8/04/36/94ff3c8a4215826a21946b34c01180817e606989fdf53f7cd6\nSuccessfully built grad-cam\nInstalling collected packages: ttach, grad-cam\nSuccessfully installed grad-cam-1.4.8 ttach-0.0.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{"id":"ewMSJXI6iOeU"}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"VKlM2dreVY9A","execution":{"iopub.status.busy":"2023-10-15T14:21:25.896175Z","iopub.execute_input":"2023-10-15T14:21:25.896535Z","iopub.status.idle":"2023-10-15T14:21:25.902257Z","shell.execute_reply.started":"2023-10-15T14:21:25.896507Z","shell.execute_reply":"2023-10-15T14:21:25.901422Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Architecture\nhttps://arxiv.org/pdf/1603.09246.pdf, Model Reference\n\nhttps://github.com/jiecaoyu/pytorch_imagenet/blob/master/networks/model_list/alexnet.py, LRN","metadata":{"id":"isNmWS3rFPsp"}},{"cell_type":"code","source":"class LRN(nn.Module):\n    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n        super(LRN, self).__init__()\n        self.ACROSS_CHANNELS = ACROSS_CHANNELS\n        if ACROSS_CHANNELS:\n            self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1),\n                    stride=1,padding=(int((local_size-1.0)/2), 0, 0))\n        else:\n            self.average=nn.AvgPool2d(kernel_size=local_size,\n                    stride=1,padding=int((local_size-1.0)/2))\n        self.alpha = alpha\n        self.beta = beta\n\n\n    def forward(self, x):\n        if self.ACROSS_CHANNELS:\n            div = x.pow(2).unsqueeze(1)\n            div = self.average(div).squeeze(1)\n            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n        else:\n            div = x.pow(2)\n            div = self.average(div)\n            div = div.mul(self.alpha).add(1.0).pow(self.beta)\n        x = x.div(div)\n        return x","metadata":{"id":"xszdPnQ9F5vU","execution":{"iopub.status.busy":"2023-10-15T14:21:28.376168Z","iopub.execute_input":"2023-10-15T14:21:28.376533Z","iopub.status.idle":"2023-10-15T14:21:28.383950Z","shell.execute_reply.started":"2023-10-15T14:21:28.376505Z","shell.execute_reply":"2023-10-15T14:21:28.382983Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('Utils')\n\nclass Model(nn.Module):\n\n    def __init__(self, classes=100):\n        super(Model, self).__init__()\n\n        self.conv = nn.Sequential()\n        self.conv.add_module('conv1_s1',nn.Conv2d(3, 96, kernel_size=11, stride=2, padding=0))\n        self.conv.add_module('relu1_s1',nn.ReLU(inplace=True))\n        self.conv.add_module('pool1_s1',nn.MaxPool2d(kernel_size=3, stride=2))\n        self.conv.add_module('lrn1_s1',LRN(local_size=5, alpha=0.0001, beta=0.75))\n\n        self.conv.add_module('conv2_s1',nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2))\n        self.conv.add_module('relu2_s1',nn.ReLU(inplace=True))\n        self.conv.add_module('pool2_s1',nn.MaxPool2d(kernel_size=3, stride=2))\n        self.conv.add_module('lrn2_s1',LRN(local_size=5, alpha=0.0001, beta=0.75))\n\n        self.conv.add_module('conv3_s1',nn.Conv2d(256, 384, kernel_size=3, padding=1))\n        self.conv.add_module('relu3_s1',nn.ReLU(inplace=True))\n\n        self.conv.add_module('conv4_s1',nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2))\n        self.conv.add_module('relu4_s1',nn.ReLU(inplace=True))\n\n        self.conv.add_module('conv5_s1',nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2))\n        self.conv.add_module('relu5_s1',nn.ReLU(inplace=True))\n        self.conv.add_module('pool5_s1',nn.MaxPool2d(kernel_size=3, stride=2))\n\n        self.fc6 = nn.Sequential()\n        self.fc6.add_module('fc6_s1',nn.Linear(256*3*3, 1024))\n        self.fc6.add_module('relu6_s1',nn.ReLU(inplace=True))\n        self.fc6.add_module('drop6_s1',nn.Dropout(p=0.5))\n\n        self.fc7 = nn.Sequential()\n        self.fc7.add_module('fc7',nn.Linear(9*1024,4096))\n        self.fc7.add_module('relu7',nn.ReLU(inplace=True))\n        self.fc7.add_module('drop7',nn.Dropout(p=0.5))\n\n        self.classifier = nn.Sequential()\n        self.classifier.add_module('fc8',nn.Linear(4096, classes))\n\n    def load(self,checkpoint):\n        model_dict = self.state_dict()\n        pretrained_dict = torch.load(checkpoint)\n        pretrained_dict = {k: v for k, v in list(pretrained_dict.items()) if k in model_dict and 'fc8' not in k}\n        model_dict.update(pretrained_dict)\n        self.load_state_dict(model_dict)\n        print([k for k, v in list(pretrained_dict.items())])\n\n    def save(self,checkpoint):\n        torch.save(self.state_dict(), checkpoint)\n\n    def forward(self, x):\n        B,T,C,H,W = x.size()\n        x = x.transpose(0,1)\n\n        x_list = []\n\n        for i in range(9):\n            z = self.conv(x[i])\n            z = self.fc6(z.view(B,-1))\n            z = z.view([B,1,-1])\n            x_list.append(z)\n\n        x = cat(x_list,1)\n        x = self.fc7(x.view(B,-1))\n        x = self.classifier(x)\n        return x\n\ndef weights_init(model):\n    if type(model) in [nn.Conv2d,nn.Linear]:\n        nn.init.xavier_normal(model.weight.data)\n        nn.init.constant(model.bias.data, 0.1)\n","metadata":{"id":"leT7FwwW7WEy","execution":{"iopub.status.busy":"2023-10-15T14:21:30.322309Z","iopub.execute_input":"2023-10-15T14:21:30.322635Z","iopub.status.idle":"2023-10-15T14:21:30.340579Z","shell.execute_reply.started":"2023-10-15T14:21:30.322611Z","shell.execute_reply":"2023-10-15T14:21:30.339663Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"nodmctD7jodm"}},{"cell_type":"code","source":"class UpsampleCIFAR10(Dataset):\n    def __init__(self, cifar_dataset, target_size=(255, 255)):\n        self.cifar_dataset = cifar_dataset\n        self.target_size = target_size\n        self.upsample_transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize(self.target_size),\n        ])\n\n    def __len__(self):\n        return len(self.cifar_dataset)\n\n    def __getitem__(self, index):\n        image, label = self.cifar_dataset[index]\n        upsampled_image = self.upsample_transform(image)\n        return upsampled_image, label","metadata":{"id":"7pr5Rw8yNgb2","execution":{"iopub.status.busy":"2023-10-15T14:21:32.255828Z","iopub.execute_input":"2023-10-15T14:21:32.256450Z","iopub.status.idle":"2023-10-15T14:21:32.263414Z","shell.execute_reply.started":"2023-10-15T14:21:32.256391Z","shell.execute_reply":"2023-10-15T14:21:32.262469Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntrainset = UpsampleCIFAR10(train)\ntestset = UpsampleCIFAR10(test)\nclasses = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ps2sdj3njo_5","outputId":"888bd391-f641-44bd-8e3e-73285f405389","execution":{"iopub.status.busy":"2023-10-15T14:21:34.573830Z","iopub.execute_input":"2023-10-15T14:21:34.574328Z","iopub.status.idle":"2023-10-15T14:21:36.200723Z","shell.execute_reply.started":"2023-10-15T14:21:34.574294Z","shell.execute_reply":"2023-10-15T14:21:36.199771Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import trange\nimport numpy as np\nimport itertools\nfrom scipy.spatial.distance import cdist\n\ndef get_permutations(classes = 1000):\n  P_hat = np.array(list(itertools.permutations(list(range(9)), 9)))\n  n = P_hat.shape[0]\n  for i in trange(classes):\n      if i==0:\n          j = np.random.randint(n)\n          P = np.array(P_hat[j]).reshape([1,-1])\n      else:\n          P = np.concatenate([P,P_hat[j].reshape([1,-1])],axis=0)\n\n      P_hat = np.delete(P_hat,j,axis=0)\n      D = cdist(P,P_hat, metric='hamming').mean(axis=0).flatten()\n      j = D.argmax()\n  return P","metadata":{"id":"ux3P_eRo6nHW","execution":{"iopub.status.busy":"2023-10-15T14:21:36.396785Z","iopub.execute_input":"2023-10-15T14:21:36.397125Z","iopub.status.idle":"2023-10-15T14:21:36.818278Z","shell.execute_reply.started":"2023-10-15T14:21:36.397099Z","shell.execute_reply":"2023-10-15T14:21:36.817338Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataLoader(data.Dataset):\n    def __init__(self, dataset, classes=100):\n        self.dataset = dataset\n        self.permutations = self.__retrive_permutations(classes)\n        self.__image_transformer = transforms.Compose([\n            transforms.Resize(256, Image.BILINEAR),\n            transforms.CenterCrop(255)])\n        self.__augment_tile = transforms.Compose([\n            transforms.RandomCrop(64),\n            transforms.Resize((75, 75), Image.BILINEAR),\n            transforms.ToTensor(),\n        ])\n\n    def __getitem__(self, index):\n        img = self.dataset[index][0].convert('RGB')\n        if np.random.rand() < 0.30:\n            img = img.convert('LA').convert('RGB')\n        if img.size[0] != 32:\n            img = self.__image_transformer(img)\n        s = float(img.size[0]) / 3\n        a = s / 2\n        tiles = [None] * 9\n        for n in range(9):\n            i = n / 3\n            j = n % 3\n            c = [a * i * 2 + a, a * j * 2 + a]\n            c = np.array([c[1] - a, c[0] - a, c[1] + a + 1, c[0] + a + 1]).astype(int)\n            tile = img.crop(c.tolist())\n            tile = self.__augment_tile(tile)\n            m, s = tile.view(3, -1).mean(dim=1).numpy(), tile.view(3, -1).std(dim=1).numpy()\n            s[s == 0] = 1\n            norm = transforms.Normalize(mean=m.tolist(), std=s.tolist())\n            tile = norm(tile)\n            tiles[n] = tile\n\n        order = np.random.randint(len(self.permutations))\n        data = [tiles[self.permutations[order][t]] for t in range(9)]\n        data = torch.stack(data, 0)\n        return data, int(order), tiles\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __retrive_permutations(self, classes):\n        return get_permutations(classes)","metadata":{"id":"h6WeFOQOqUvL","execution":{"iopub.status.busy":"2023-10-15T14:21:38.023191Z","iopub.execute_input":"2023-10-15T14:21:38.023569Z","iopub.status.idle":"2023-10-15T14:21:38.035152Z","shell.execute_reply.started":"2023-10-15T14:21:38.023542Z","shell.execute_reply":"2023-10-15T14:21:38.034164Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_data = DataLoader(trainset)\ntest_data = DataLoader(testset)\ntrain_loader = torch.utils.data.DataLoader(dataset= train_data,\n                                           batch_size=batch_size,\n                                           shuffle=True,\n                                           num_workers=2)\ntest_loader = torch.utils.data.DataLoader(dataset = test_data,\n                                          batch_size=batch_size,\n                                          shuffle=False,\n                                          num_workers=2)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DXxOFeo8jGk","outputId":"7a8b72c4-19d1-4ac2-ae6a-23f5bd93ec1f","execution":{"iopub.status.busy":"2023-10-15T14:21:39.789442Z","iopub.execute_input":"2023-10-15T14:21:39.789786Z","iopub.status.idle":"2023-10-15T14:22:26.997193Z","shell.execute_reply.started":"2023-10-15T14:21:39.789759Z","shell.execute_reply":"2023-10-15T14:22:26.996199Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [00:22<00:00,  4.38it/s]\n100%|██████████| 100/100 [00:23<00:00,  4.24it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, (image, label, original) in enumerate(train_loader):\n  print(i, image.shape, label.shape)\n  break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib_X6ud1Sw1M","outputId":"581f78b1-73ce-4584-ffdb-170205b84fb6","execution":{"iopub.status.busy":"2023-10-15T14:23:03.465088Z","iopub.execute_input":"2023-10-15T14:23:03.465443Z","iopub.status.idle":"2023-10-15T14:23:05.538325Z","shell.execute_reply.started":"2023-10-15T14:23:03.465414Z","shell.execute_reply":"2023-10-15T14:23:05.537090Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"0 torch.Size([64, 9, 3, 75, 75]) torch.Size([64])\n","output_type":"stream"}]},{"cell_type":"code","source":"N = len(train_data.dataset)\niter_per_epoch = N / batch_size","metadata":{"id":"abjLWboLQCJ5","execution":{"iopub.status.busy":"2023-10-11T11:54:22.187702Z","iopub.execute_input":"2023-10-11T11:54:22.188066Z","iopub.status.idle":"2023-10-11T11:54:22.193753Z","shell.execute_reply.started":"2023-10-11T11:54:22.188030Z","shell.execute_reply":"2023-10-11T11:54:22.192418Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = Model(100)\nmodel.cuda()","metadata":{"id":"q43dx2USCz2Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"df1f9d39-af8b-4ea7-ebfc-b0d5b1a52780","execution":{"iopub.status.busy":"2023-10-11T11:54:22.195139Z","iopub.execute_input":"2023-10-11T11:54:22.196263Z","iopub.status.idle":"2023-10-11T11:54:25.758482Z","shell.execute_reply.started":"2023-10-11T11:54:22.196230Z","shell.execute_reply":"2023-10-11T11:54:25.757525Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Model(\n  (conv): Sequential(\n    (conv1_s1): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2))\n    (relu1_s1): ReLU(inplace=True)\n    (pool1_s1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (lrn1_s1): LRN(\n      (average): AvgPool3d(kernel_size=(5, 1, 1), stride=1, padding=(2, 0, 0))\n    )\n    (conv2_s1): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n    (relu2_s1): ReLU(inplace=True)\n    (pool2_s1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (lrn2_s1): LRN(\n      (average): AvgPool3d(kernel_size=(5, 1, 1), stride=1, padding=(2, 0, 0))\n    )\n    (conv3_s1): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (relu3_s1): ReLU(inplace=True)\n    (conv4_s1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n    (relu4_s1): ReLU(inplace=True)\n    (conv5_s1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n    (relu5_s1): ReLU(inplace=True)\n    (pool5_s1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc6): Sequential(\n    (fc6_s1): Linear(in_features=2304, out_features=1024, bias=True)\n    (relu6_s1): ReLU(inplace=True)\n    (drop6_s1): Dropout(p=0.5, inplace=False)\n  )\n  (fc7): Sequential(\n    (fc7): Linear(in_features=9216, out_features=4096, bias=True)\n    (relu7): ReLU(inplace=True)\n    (drop7): Dropout(p=0.5, inplace=False)\n  )\n  (classifier): Sequential(\n    (fc8): Linear(in_features=4096, out_features=100, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def compute_accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res","metadata":{"id":"Zt1CtfwNIK9d","execution":{"iopub.status.busy":"2023-10-11T11:54:25.760026Z","iopub.execute_input":"2023-10-11T11:54:25.760406Z","iopub.status.idle":"2023-10-11T11:54:25.767315Z","shell.execute_reply.started":"2023-10-11T11:54:25.760335Z","shell.execute_reply":"2023-10-11T11:54:25.766237Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"dqlfDmhUFZCK"}},{"cell_type":"code","source":"import time\nnum_epochs = 20\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3,momentum=0.9, weight_decay=5e-4)\nfor epoch in range(num_epochs):\n  t= time.time()\n  for i, (images, labels, original) in enumerate(train_loader):\n    images = Variable(images)\n    labels = Variable(labels)\n    images = images.cuda()\n    labels = labels.cuda()\n    optimizer.zero_grad()\n    outputs = model(images)\n    prec1 = compute_accuracy(outputs.cpu().data, labels.cpu().data, topk=(1,))\n    acc = prec1[0]\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n    loss = float(loss.cpu().data.numpy())\n  print(f\"Epoch {epoch}---Step{i+1} --- Accuracy {acc} --- Time:{time.time()-t}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvpnzM0VFpYd","outputId":"b6e7f0b3-4399-4dce-df69-2a421d663a09","execution":{"iopub.status.busy":"2023-10-11T11:54:25.768808Z","iopub.execute_input":"2023-10-11T11:54:25.769484Z","iopub.status.idle":"2023-10-11T14:47:48.256975Z","shell.execute_reply.started":"2023-10-11T11:54:25.769450Z","shell.execute_reply":"2023-10-11T14:47:48.255609Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 0---Step782 --- Accuracy 0.0 --- Time:512.2298622131348\nEpoch 1---Step782 --- Accuracy 0.0 --- Time:506.73582434654236\nEpoch 2---Step782 --- Accuracy 0.0 --- Time:497.7326593399048\nEpoch 3---Step782 --- Accuracy 43.75 --- Time:508.00422072410583\nEpoch 4---Step782 --- Accuracy 75.0 --- Time:503.73362922668457\nEpoch 5---Step782 --- Accuracy 50.0 --- Time:492.6442952156067\nEpoch 6---Step782 --- Accuracy 75.0 --- Time:531.9372880458832\nEpoch 7---Step782 --- Accuracy 81.25 --- Time:527.133204460144\nEpoch 8---Step782 --- Accuracy 68.75 --- Time:529.0457561016083\nEpoch 9---Step782 --- Accuracy 56.25 --- Time:529.8386704921722\nEpoch 10---Step782 --- Accuracy 50.0 --- Time:524.7993161678314\nEpoch 11---Step782 --- Accuracy 93.75 --- Time:522.6460123062134\nEpoch 12---Step782 --- Accuracy 87.5 --- Time:521.074241399765\nEpoch 13---Step782 --- Accuracy 75.0 --- Time:511.4657597541809\nEpoch 14---Step782 --- Accuracy 68.75 --- Time:526.6302170753479\nEpoch 15---Step782 --- Accuracy 62.5 --- Time:526.8340213298798\nEpoch 16---Step782 --- Accuracy 68.75 --- Time:528.4755516052246\nEpoch 17---Step782 --- Accuracy 68.75 --- Time:528.8287036418915\nEpoch 18---Step782 --- Accuracy 68.75 --- Time:539.0583233833313\nEpoch 19---Step782 --- Accuracy 75.0 --- Time:533.621524810791\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, \"CFN.pt\")","metadata":{"id":"xSGQmU8lKBQX","execution":{"iopub.status.busy":"2023-10-11T14:58:37.010319Z","iopub.execute_input":"2023-10-11T14:58:37.010886Z","iopub.status.idle":"2023-10-11T14:58:37.457525Z","shell.execute_reply.started":"2023-10-11T14:58:37.010838Z","shell.execute_reply":"2023-10-11T14:58:37.456358Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"!ls data/","metadata":{"execution":{"iopub.status.busy":"2023-10-15T14:28:20.937480Z","iopub.execute_input":"2023-10-15T14:28:20.937843Z","iopub.status.idle":"2023-10-15T14:28:21.965490Z","shell.execute_reply.started":"2023-10-15T14:28:20.937815Z","shell.execute_reply":"2023-10-15T14:28:21.964312Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"cifar-10-batches-py  cifar-10-python.tar.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"uploaded_model = torch.load(\"/kaggle/input/weights/CFN.pt\")\nuploaded_model.eval()","metadata":{"id":"_C6qQWSfMFVZ","execution":{"iopub.status.busy":"2023-10-15T14:28:52.785873Z","iopub.execute_input":"2023-10-15T14:28:52.786244Z","iopub.status.idle":"2023-10-15T14:28:56.173974Z","shell.execute_reply.started":"2023-10-15T14:28:52.786213Z","shell.execute_reply":"2023-10-15T14:28:56.172955Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"Model(\n  (conv): Sequential(\n    (conv1_s1): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2))\n    (relu1_s1): ReLU(inplace=True)\n    (pool1_s1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (lrn1_s1): LRN(\n      (average): AvgPool3d(kernel_size=(5, 1, 1), stride=1, padding=(2, 0, 0))\n    )\n    (conv2_s1): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n    (relu2_s1): ReLU(inplace=True)\n    (pool2_s1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (lrn2_s1): LRN(\n      (average): AvgPool3d(kernel_size=(5, 1, 1), stride=1, padding=(2, 0, 0))\n    )\n    (conv3_s1): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (relu3_s1): ReLU(inplace=True)\n    (conv4_s1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n    (relu4_s1): ReLU(inplace=True)\n    (conv5_s1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n    (relu5_s1): ReLU(inplace=True)\n    (pool5_s1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc6): Sequential(\n    (fc6_s1): Linear(in_features=2304, out_features=1024, bias=True)\n    (relu6_s1): ReLU(inplace=True)\n    (drop6_s1): Dropout(p=0.5, inplace=False)\n  )\n  (fc7): Sequential(\n    (fc7): Linear(in_features=9216, out_features=4096, bias=True)\n    (relu7): ReLU(inplace=True)\n    (drop7): Dropout(p=0.5, inplace=False)\n  )\n  (classifier): Sequential(\n    (fc8): Linear(in_features=4096, out_features=100, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Gradcam Analysis","metadata":{}},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"for i, (image, label, original) in enumerate(train_loader):\n  pass\n  if i == 10:\n    break\nfrom pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\nmodel = uploaded_model\ntarget_layers = [model.conv[-1]]\ninput_tensor = image\ncam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n\ntargets = [ClassifierOutputTarget(label[i])]\n\ngrayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n\ngrayscale_cam = grayscale_cam[0, :]\nplt.imshow(grayscale_cam)\n# plt.show()\n# plt.imshow(image[0][0].permute(1,2,0))\n# visualization = show_cam_on_image(image[0][0], grayscale_cam, use_rgb=False)","metadata":{"id":"DgdrKDfHMFTk","execution":{"iopub.status.busy":"2023-10-15T14:30:04.627546Z","iopub.execute_input":"2023-10-15T14:30:04.627894Z","iopub.status.idle":"2023-10-15T14:30:12.559529Z","shell.execute_reply.started":"2023-10-15T14:30:04.627866Z","shell.execute_reply":"2023-10-15T14:30:12.558452Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x797a462110c0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"P0ZbjHk7MFRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"K6OHfKEiMFPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"J7-CCR-HMFLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YH7tcyhzMFy6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"uUxoZhIRMNYj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"b-TLYFaUMSDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8__0Dt2gMifu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"KgbpEMzSMkF8"},"execution_count":null,"outputs":[]}]}